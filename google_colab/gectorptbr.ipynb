{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"gectorptbr.ipynb","provenance":[],"collapsed_sections":["WXGrJP0kqudE","PyHPSY58b4I7","Ofd2TWLWmaX0","NfyzbfEAmosK","2IWPdrrRmvyV","krjxz4M52Nv0"],"mount_file_id":"1p6PeHmbknEPlepX24EhfQRpOgHG-RmVg","authorship_tag":"ABX9TyNB95WB+aMOEeev2B+qN11C"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3n19S0m4EMMS","outputId":"d93766cf-53c1-4ee9-b8a2-042e2e3d031b"},"source":["!cd /content/drive/MyDrive/gectorptbrFolder && git pull https://SchmitzErnany:7299acad80a508fb03a611716b838fe858909439@github.com/SchmitzErnany/gectorptbrFolder.git"],"execution_count":null,"outputs":[{"output_type":"stream","text":["remote: Enumerating objects: 7, done.\u001b[K\n","remote: Counting objects:  14% (1/7)\u001b[K\rremote: Counting objects:  28% (2/7)\u001b[K\rremote: Counting objects:  42% (3/7)\u001b[K\rremote: Counting objects:  57% (4/7)\u001b[K\rremote: Counting objects:  71% (5/7)\u001b[K\rremote: Counting objects:  85% (6/7)\u001b[K\rremote: Counting objects: 100% (7/7)\u001b[K\rremote: Counting objects: 100% (7/7), done.\u001b[K\n","remote: Compressing objects:  50% (1/2)\u001b[K\rremote: Compressing objects: 100% (2/2)\u001b[K\rremote: Compressing objects: 100% (2/2), done.\u001b[K\n","remote: Total 4 (delta 3), reused 3 (delta 2), pack-reused 0\u001b[K\n","Unpacking objects: 100% (4/4), done.\n","From https://github.com/SchmitzErnany/gectorptbrFolder\n"," * branch            HEAD       -> FETCH_HEAD\n","Updating 16a9f76..c680ecd\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"wC2lDRMZjXSC"},"source":["!cd /content/drive/MyDrive/gectorptbrFolder && git status"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"WXGrJP0kqudE"},"source":["# **Data download**\n","\n","> Download the data from its storage place into the Google Colab working directory\n","\n"]},{"cell_type":"markdown","metadata":{"id":"PyHPSY58b4I7"},"source":["## *Data stored in a GCS Bucket*"]},{"cell_type":"markdown","metadata":{"id":"Ofd2TWLWmaX0"},"source":["### Log into the google account and initialize gcloud SDK\n","\n","> Make sure to have a google account for authentication\n","\n"]},{"cell_type":"code","metadata":{"id":"NUdjqdFc172X","colab":{"base_uri":"https://localhost:8080/","height":573},"executionInfo":{"status":"error","timestamp":1624505385487,"user_tz":180,"elapsed":100085,"user":{"displayName":"Ernany Schmitz","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhByvIFGp3xzbbo2QbRqZJxU3jtyMeDGqCBL-t8La0m3FA6rlaZPZ8a5QPtL6uQFcRZ1OshlrWUf1_aPWm6uytMFTa4X4lF-JqpwAMHUH8CbtaCNG_hQq2QjR2Z5LxSEFSoy7vxYVUIvx8fHuuANAuYr3dmW2sb1m4e55QnCBZ8gk5a5YtMqdhoVkrKOxjeKzEfpGat-YdjbHubeBi1MG6YCfCbHwVPc5LOeOQOoJNtIusrgRKb0kfP7Vg2wnfBj--No1mJWDfxPV_IzSZqNUfqwqYg3C7DprDTXUWU9x9Cj1YzBd8U0bNvEyVGGwoHAvGGlR2hp3MDNBbmbdO1oDzwGckubTeS3agumyTIYwzlL01cOe4MH8NC899KJYyE5AVd3xG2v2hyfZTPzMToGVtIKrUyXht92_Bi5-RBJyMN7PJuRwRQW7BRXpv2eXj2KQv2dB7yMBI8mJeXTaGwp8qc5HyKjjGviWKrHXxVIm6ZbW94N3MJ4kDUu55Q5qjYX-VdTBGf1pU7apC1omVbtfgOhnNI1YbJpdb4aotD4wOuBBlrlUMmknymUCCC5rhZa27vp-l4A4EgLcRBYh8SxKuzSWHA15FqlmhJU4IZoIjga55k8qfhuNulwlVgSqXHvVSOmeLNDw5fi_QapuxA8dp0KBLaCskDBidRNtbthV5nr4_poYisdAgc_LwgDhbJl14kZ3xJe-JQ68S77-jLtxI_21jDYM_YMXBnsKpLKrBFYMPNX-ZqQUdn-8hyogyV-Z14kA=s64","userId":"06748672095417157324"}},"outputId":"f5d76059-8919-41cd-f145-1ca8d571b687"},"source":["import os, subprocess\n","\n","### authenticate into google account (must have a google account)\n","from google.colab import auth\n","auth.authenticate_user()\n","### install GCloud SDK\n","!curl https://sdk.cloud.google.com | bash\n","### initialize SDK\n","!gcloud init"],"execution_count":22,"outputs":[{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m    728\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 729\u001b[0;31m                 \u001b[0mident\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreply\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstdin_socket\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    730\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/jupyter_client/session.py\u001b[0m in \u001b[0;36mrecv\u001b[0;34m(self, socket, mode, content, copy)\u001b[0m\n\u001b[1;32m    802\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 803\u001b[0;31m             \u001b[0mmsg_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msocket\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_multipart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    804\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mzmq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mZMQError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/zmq/sugar/socket.py\u001b[0m in \u001b[0;36mrecv_multipart\u001b[0;34m(self, flags, copy, track)\u001b[0m\n\u001b[1;32m    582\u001b[0m         \"\"\"\n\u001b[0;32m--> 583\u001b[0;31m         \u001b[0mparts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflags\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrack\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrack\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    584\u001b[0m         \u001b[0;31m# have first part already, only loop while more to receive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket.Socket.recv\u001b[0;34m()\u001b[0m\n","\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket.Socket.recv\u001b[0;34m()\u001b[0m\n","\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket._recv_copy\u001b[0;34m()\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/zmq/backend/cython/checkrc.pxd\u001b[0m in \u001b[0;36mzmq.backend.cython.checkrc._check_rc\u001b[0;34m()\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: ","\nDuring handling of the above exception, another exception occurred:\n","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-22-09112adf9de2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m### authenticate into google account (must have a google account)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mauth\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mauth\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauthenticate_user\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;31m### install GCloud SDK\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msystem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'curl https://sdk.cloud.google.com | bash'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/google/colab/auth.py\u001b[0m in \u001b[0;36mauthenticate_user\u001b[0;34m(clear_output)\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0mcontext_manager\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtemporary\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mclear_output\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0m_noop\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    150\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mcontext_manager\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 151\u001b[0;31m       \u001b[0m_gcloud_login\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    152\u001b[0m     \u001b[0m_install_adc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    153\u001b[0m     \u001b[0mcolab_tpu_addr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_os\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menviron\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'COLAB_TPU_ADDR'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/google/colab/auth.py\u001b[0m in \u001b[0;36m_gcloud_login\u001b[0;34m()\u001b[0m\n\u001b[1;32m     93\u001b[0m     \u001b[0;31m# https://github.com/jupyter/notebook/issues/3159\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m     \u001b[0mprompt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprompt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 95\u001b[0;31m     \u001b[0mcode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_code\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprompt\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' '\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     96\u001b[0m     \u001b[0mgcloud_process\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcommunicate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m   \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36mraw_input\u001b[0;34m(self, prompt)\u001b[0m\n\u001b[1;32m    702\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_ident\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    703\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_header\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 704\u001b[0;31m             \u001b[0mpassword\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    705\u001b[0m         )\n\u001b[1;32m    706\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m    732\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    733\u001b[0m                 \u001b[0;31m# re-raise KeyboardInterrupt, to truncate traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 734\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    735\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    736\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"markdown","metadata":{"id":"NfyzbfEAmosK"},"source":["### Set the name of the Google Cloud Storage Bucket\n","\n","> This directory must have already been created through the Google Cloud Platform\n","\n"]},{"cell_type":"code","metadata":{"id":"OyCDndfQmj_0","executionInfo":{"status":"aborted","timestamp":1624505385473,"user_tz":180,"elapsed":68,"user":{"displayName":"Ernany Schmitz","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhByvIFGp3xzbbo2QbRqZJxU3jtyMeDGqCBL-t8La0m3FA6rlaZPZ8a5QPtL6uQFcRZ1OshlrWUf1_aPWm6uytMFTa4X4lF-JqpwAMHUH8CbtaCNG_hQq2QjR2Z5LxSEFSoy7vxYVUIvx8fHuuANAuYr3dmW2sb1m4e55QnCBZ8gk5a5YtMqdhoVkrKOxjeKzEfpGat-YdjbHubeBi1MG6YCfCbHwVPc5LOeOQOoJNtIusrgRKb0kfP7Vg2wnfBj--No1mJWDfxPV_IzSZqNUfqwqYg3C7DprDTXUWU9x9Cj1YzBd8U0bNvEyVGGwoHAvGGlR2hp3MDNBbmbdO1oDzwGckubTeS3agumyTIYwzlL01cOe4MH8NC899KJYyE5AVd3xG2v2hyfZTPzMToGVtIKrUyXht92_Bi5-RBJyMN7PJuRwRQW7BRXpv2eXj2KQv2dB7yMBI8mJeXTaGwp8qc5HyKjjGviWKrHXxVIm6ZbW94N3MJ4kDUu55Q5qjYX-VdTBGf1pU7apC1omVbtfgOhnNI1YbJpdb4aotD4wOuBBlrlUMmknymUCCC5rhZa27vp-l4A4EgLcRBYh8SxKuzSWHA15FqlmhJU4IZoIjga55k8qfhuNulwlVgSqXHvVSOmeLNDw5fi_QapuxA8dp0KBLaCskDBidRNtbthV5nr4_poYisdAgc_LwgDhbJl14kZ3xJe-JQ68S77-jLtxI_21jDYM_YMXBnsKpLKrBFYMPNX-ZqQUdn-8hyogyV-Z14kA=s64","userId":"06748672095417157324"}}},"source":["### define the Google Cloud Storage Bucket\n","BUCKET = 'gectorptbrstorage'"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"2IWPdrrRmvyV"},"source":["### Download the file to be preprocessed\n","\n","> This file will be copied from the GCS Bucket into the Google Colab working directory\n","\n"]},{"cell_type":"code","metadata":{"id":"F-f1IOL2mvDI","executionInfo":{"status":"aborted","timestamp":1624505385478,"user_tz":180,"elapsed":68,"user":{"displayName":"Ernany Schmitz","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhByvIFGp3xzbbo2QbRqZJxU3jtyMeDGqCBL-t8La0m3FA6rlaZPZ8a5QPtL6uQFcRZ1OshlrWUf1_aPWm6uytMFTa4X4lF-JqpwAMHUH8CbtaCNG_hQq2QjR2Z5LxSEFSoy7vxYVUIvx8fHuuANAuYr3dmW2sb1m4e55QnCBZ8gk5a5YtMqdhoVkrKOxjeKzEfpGat-YdjbHubeBi1MG6YCfCbHwVPc5LOeOQOoJNtIusrgRKb0kfP7Vg2wnfBj--No1mJWDfxPV_IzSZqNUfqwqYg3C7DprDTXUWU9x9Cj1YzBd8U0bNvEyVGGwoHAvGGlR2hp3MDNBbmbdO1oDzwGckubTeS3agumyTIYwzlL01cOe4MH8NC899KJYyE5AVd3xG2v2hyfZTPzMToGVtIKrUyXht92_Bi5-RBJyMN7PJuRwRQW7BRXpv2eXj2KQv2dB7yMBI8mJeXTaGwp8qc5HyKjjGviWKrHXxVIm6ZbW94N3MJ4kDUu55Q5qjYX-VdTBGf1pU7apC1omVbtfgOhnNI1YbJpdb4aotD4wOuBBlrlUMmknymUCCC5rhZa27vp-l4A4EgLcRBYh8SxKuzSWHA15FqlmhJU4IZoIjga55k8qfhuNulwlVgSqXHvVSOmeLNDw5fi_QapuxA8dp0KBLaCskDBidRNtbthV5nr4_poYisdAgc_LwgDhbJl14kZ3xJe-JQ68S77-jLtxI_21jDYM_YMXBnsKpLKrBFYMPNX-ZqQUdn-8hyogyV-Z14kA=s64","userId":"06748672095417157324"}}},"source":["### download sentences file\n","os.system('gsutil cp gs://' + BUCKET + '/files/wiki-sentences.txt .');"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ORHOMxh4pfiW"},"source":["## *Data stored in a Google Drive*"]},{"cell_type":"markdown","metadata":{"id":"xzo0RM99pwms"},"source":["### Download the file to be preprocessed\n","\n","> This file will be copied from a Google Drive into the Google Colab working directory"]},{"cell_type":"code","metadata":{"id":"eLl6F7Hap3bd","executionInfo":{"status":"aborted","timestamp":1624505385481,"user_tz":180,"elapsed":68,"user":{"displayName":"Ernany Schmitz","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhByvIFGp3xzbbo2QbRqZJxU3jtyMeDGqCBL-t8La0m3FA6rlaZPZ8a5QPtL6uQFcRZ1OshlrWUf1_aPWm6uytMFTa4X4lF-JqpwAMHUH8CbtaCNG_hQq2QjR2Z5LxSEFSoy7vxYVUIvx8fHuuANAuYr3dmW2sb1m4e55QnCBZ8gk5a5YtMqdhoVkrKOxjeKzEfpGat-YdjbHubeBi1MG6YCfCbHwVPc5LOeOQOoJNtIusrgRKb0kfP7Vg2wnfBj--No1mJWDfxPV_IzSZqNUfqwqYg3C7DprDTXUWU9x9Cj1YzBd8U0bNvEyVGGwoHAvGGlR2hp3MDNBbmbdO1oDzwGckubTeS3agumyTIYwzlL01cOe4MH8NC899KJYyE5AVd3xG2v2hyfZTPzMToGVtIKrUyXht92_Bi5-RBJyMN7PJuRwRQW7BRXpv2eXj2KQv2dB7yMBI8mJeXTaGwp8qc5HyKjjGviWKrHXxVIm6ZbW94N3MJ4kDUu55Q5qjYX-VdTBGf1pU7apC1omVbtfgOhnNI1YbJpdb4aotD4wOuBBlrlUMmknymUCCC5rhZa27vp-l4A4EgLcRBYh8SxKuzSWHA15FqlmhJU4IZoIjga55k8qfhuNulwlVgSqXHvVSOmeLNDw5fi_QapuxA8dp0KBLaCskDBidRNtbthV5nr4_poYisdAgc_LwgDhbJl14kZ3xJe-JQ68S77-jLtxI_21jDYM_YMXBnsKpLKrBFYMPNX-ZqQUdn-8hyogyV-Z14kA=s64","userId":"06748672095417157324"}}},"source":["import os\n","\n","### download sentences file\n","os.system('cp /content/drive/MyDrive/gectorptbrFolder/preprocessable_files/wiki-sentences.txt .');"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"PAZ-5r77dKqJ"},"source":["# **Errorify the data**\n","\n","> Synthetically produce errors into the dataset and save two files in the folder dual_files/, one is for correct sentences and the other is for the errorified sentences\n","\n"]},{"cell_type":"code","metadata":{"id":"G1z2vOxPtn3_","executionInfo":{"status":"aborted","timestamp":1624505385483,"user_tz":180,"elapsed":67,"user":{"displayName":"Ernany Schmitz","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhByvIFGp3xzbbo2QbRqZJxU3jtyMeDGqCBL-t8La0m3FA6rlaZPZ8a5QPtL6uQFcRZ1OshlrWUf1_aPWm6uytMFTa4X4lF-JqpwAMHUH8CbtaCNG_hQq2QjR2Z5LxSEFSoy7vxYVUIvx8fHuuANAuYr3dmW2sb1m4e55QnCBZ8gk5a5YtMqdhoVkrKOxjeKzEfpGat-YdjbHubeBi1MG6YCfCbHwVPc5LOeOQOoJNtIusrgRKb0kfP7Vg2wnfBj--No1mJWDfxPV_IzSZqNUfqwqYg3C7DprDTXUWU9x9Cj1YzBd8U0bNvEyVGGwoHAvGGlR2hp3MDNBbmbdO1oDzwGckubTeS3agumyTIYwzlL01cOe4MH8NC899KJYyE5AVd3xG2v2hyfZTPzMToGVtIKrUyXht92_Bi5-RBJyMN7PJuRwRQW7BRXpv2eXj2KQv2dB7yMBI8mJeXTaGwp8qc5HyKjjGviWKrHXxVIm6ZbW94N3MJ4kDUu55Q5qjYX-VdTBGf1pU7apC1omVbtfgOhnNI1YbJpdb4aotD4wOuBBlrlUMmknymUCCC5rhZa27vp-l4A4EgLcRBYh8SxKuzSWHA15FqlmhJU4IZoIjga55k8qfhuNulwlVgSqXHvVSOmeLNDw5fi_QapuxA8dp0KBLaCskDBidRNtbthV5nr4_poYisdAgc_LwgDhbJl14kZ3xJe-JQ68S77-jLtxI_21jDYM_YMXBnsKpLKrBFYMPNX-ZqQUdn-8hyogyV-Z14kA=s64","userId":"06748672095417157324"}}},"source":["### errorify the wiki-sentences.txt file\n","!cd /content/drive/MyDrive/gectorptbrFolder/PIE/errorify/ptbr && python3 error.py /content/wiki-sentences.txt /content/drive/MyDrive/gectorptbrFolder/files/dual_files"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"krjxz4M52Nv0"},"source":["# **Install pip3 dependencies**\n","\n","> The following two sections depend on these packages\n","\n"]},{"cell_type":"code","metadata":{"id":"xUu2ku9o2M0X","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1624507314828,"user_tz":180,"elapsed":114034,"user":{"displayName":"Ernany Schmitz","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhByvIFGp3xzbbo2QbRqZJxU3jtyMeDGqCBL-t8La0m3FA6rlaZPZ8a5QPtL6uQFcRZ1OshlrWUf1_aPWm6uytMFTa4X4lF-JqpwAMHUH8CbtaCNG_hQq2QjR2Z5LxSEFSoy7vxYVUIvx8fHuuANAuYr3dmW2sb1m4e55QnCBZ8gk5a5YtMqdhoVkrKOxjeKzEfpGat-YdjbHubeBi1MG6YCfCbHwVPc5LOeOQOoJNtIusrgRKb0kfP7Vg2wnfBj--No1mJWDfxPV_IzSZqNUfqwqYg3C7DprDTXUWU9x9Cj1YzBd8U0bNvEyVGGwoHAvGGlR2hp3MDNBbmbdO1oDzwGckubTeS3agumyTIYwzlL01cOe4MH8NC899KJYyE5AVd3xG2v2hyfZTPzMToGVtIKrUyXht92_Bi5-RBJyMN7PJuRwRQW7BRXpv2eXj2KQv2dB7yMBI8mJeXTaGwp8qc5HyKjjGviWKrHXxVIm6ZbW94N3MJ4kDUu55Q5qjYX-VdTBGf1pU7apC1omVbtfgOhnNI1YbJpdb4aotD4wOuBBlrlUMmknymUCCC5rhZa27vp-l4A4EgLcRBYh8SxKuzSWHA15FqlmhJU4IZoIjga55k8qfhuNulwlVgSqXHvVSOmeLNDw5fi_QapuxA8dp0KBLaCskDBidRNtbthV5nr4_poYisdAgc_LwgDhbJl14kZ3xJe-JQ68S77-jLtxI_21jDYM_YMXBnsKpLKrBFYMPNX-ZqQUdn-8hyogyV-Z14kA=s64","userId":"06748672095417157324"}},"outputId":"1394afdd-aff1-489d-b4f4-295f85e27509"},"source":["### install the package requirements\n","!pip3 install -q -r /content/drive/MyDrive/gectorptbrFolder/requirements.txt"],"execution_count":2,"outputs":[{"output_type":"stream","text":["\u001b[K     |████████████████████████████████| 5.7MB 5.8MB/s \n","\u001b[33mWARNING: The candidate selected for download or install is a yanked version: 'python-Levenshtein' candidate (version 0.12.0 at https://files.pythonhosted.org/packages/42/a9/d1785c85ebf9b7dfacd08938dd028209c34a0ea3b1bcdb895208bd40a67d/python-Levenshtein-0.12.0.tar.gz#sha256=033a11de5e3d19ea25c9302d11224e1a1898fe5abd23c61c7c360c25195e3eb1 (from https://pypi.org/simple/python-levenshtein/))\n","Reason for being yanked: Insecure, upgrade to 0.12.1\u001b[0m\n","\u001b[K     |████████████████████████████████| 51kB 8.4MB/s \n","\u001b[K     |████████████████████████████████| 389kB 47.4MB/s \n","\u001b[K     |████████████████████████████████| 1.1MB 51.3MB/s \n","\u001b[K     |████████████████████████████████| 51kB 8.5MB/s \n","\u001b[K     |████████████████████████████████| 266kB 41.8MB/s \n","\u001b[K     |████████████████████████████████| 30.8MB 90kB/s \n","\u001b[K     |████████████████████████████████| 122kB 59.5MB/s \n","\u001b[K     |████████████████████████████████| 245kB 59.2MB/s \n","\u001b[K     |████████████████████████████████| 133kB 54.4MB/s \n","\u001b[K     |████████████████████████████████| 3.6MB 44.9MB/s \n","\u001b[K     |████████████████████████████████| 71kB 11.8MB/s \n","\u001b[K     |████████████████████████████████| 5.6MB 46.6MB/s \n","\u001b[K     |████████████████████████████████| 133kB 56.0MB/s \n","\u001b[K     |████████████████████████████████| 51kB 8.1MB/s \n","\u001b[K     |████████████████████████████████| 901kB 43.0MB/s \n","\u001b[K     |████████████████████████████████| 2.1MB 47.4MB/s \n","\u001b[K     |████████████████████████████████| 3.2MB 44.9MB/s \n","\u001b[K     |████████████████████████████████| 92kB 12.8MB/s \n","\u001b[K     |████████████████████████████████| 81kB 8.4MB/s \n","\u001b[K     |████████████████████████████████| 7.6MB 43.0MB/s \n","\u001b[K     |████████████████████████████████| 552kB 45.9MB/s \n","\u001b[K     |████████████████████████████████| 256kB 59.9MB/s \n","\u001b[?25h  Building wheel for python-Levenshtein (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Building wheel for parsimonious (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Building wheel for jsonnet (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Building wheel for word2number (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Building wheel for ftfy (setup.py) ... \u001b[?25l\u001b[?25hdone\n","\u001b[31mERROR: en-core-web-sm 2.2.5 has requirement spacy>=2.2.2, but you'll have spacy 2.1.9 which is incompatible.\u001b[0m\n","\u001b[31mERROR: datascience 0.10.6 has requirement folium==0.2.1, but you'll have folium 0.8.3 which is incompatible.\u001b[0m\n","\u001b[31mERROR: botocore 1.20.99 has requirement urllib3<1.27,>=1.25.4, but you'll have urllib3 1.24.3 which is incompatible.\u001b[0m\n","\u001b[31mERROR: responses 0.13.3 has requirement urllib3>=1.25.10, but you'll have urllib3 1.24.3 which is incompatible.\u001b[0m\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"o1PFWKn1dTfN"},"source":["# **Compare the dual files**\n","> In this step, we compare the correct sentences against the errorified sentences in order to create a dataset which has inputs alongside the respective labels, for example: **Eu vou a{replace_à} praia...** . In this example, **a** is the input and its label is **replace_à**. This process creates the training file for Deep Learning.\n","\n","\n","\n"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"i4I5Vdyl3goE","executionInfo":{"status":"ok","timestamp":1624506686708,"user_tz":180,"elapsed":867240,"user":{"displayName":"Ernany Schmitz","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhByvIFGp3xzbbo2QbRqZJxU3jtyMeDGqCBL-t8La0m3FA6rlaZPZ8a5QPtL6uQFcRZ1OshlrWUf1_aPWm6uytMFTa4X4lF-JqpwAMHUH8CbtaCNG_hQq2QjR2Z5LxSEFSoy7vxYVUIvx8fHuuANAuYr3dmW2sb1m4e55QnCBZ8gk5a5YtMqdhoVkrKOxjeKzEfpGat-YdjbHubeBi1MG6YCfCbHwVPc5LOeOQOoJNtIusrgRKb0kfP7Vg2wnfBj--No1mJWDfxPV_IzSZqNUfqwqYg3C7DprDTXUWU9x9Cj1YzBd8U0bNvEyVGGwoHAvGGlR2hp3MDNBbmbdO1oDzwGckubTeS3agumyTIYwzlL01cOe4MH8NC899KJYyE5AVd3xG2v2hyfZTPzMToGVtIKrUyXht92_Bi5-RBJyMN7PJuRwRQW7BRXpv2eXj2KQv2dB7yMBI8mJeXTaGwp8qc5HyKjjGviWKrHXxVIm6ZbW94N3MJ4kDUu55Q5qjYX-VdTBGf1pU7apC1omVbtfgOhnNI1YbJpdb4aotD4wOuBBlrlUMmknymUCCC5rhZa27vp-l4A4EgLcRBYh8SxKuzSWHA15FqlmhJU4IZoIjga55k8qfhuNulwlVgSqXHvVSOmeLNDw5fi_QapuxA8dp0KBLaCskDBidRNtbthV5nr4_poYisdAgc_LwgDhbJl14kZ3xJe-JQ68S77-jLtxI_21jDYM_YMXBnsKpLKrBFYMPNX-ZqQUdn-8hyogyV-Z14kA=s64","userId":"06748672095417157324"}},"outputId":"44633417-ce9a-48c9-89c0-bab79f6485c1"},"source":["### generate source file for training\n","!cd /content/drive/MyDrive/gectorptbrFolder && python3 utils/preprocess_data.py -s files/dual_files/corr_sentences.txt -t files/dual_files/incorr_sentences.txt -o files/neural_files/inputs_labels.txt"],"execution_count":27,"outputs":[{"output_type":"stream","text":["The size of raw dataset is 5409120 file lines\n","100% 5409120/5409120 [14:08<00:00, 6377.40it/s]\n","Overall extracted 5409120. Original TP 2408131. Original TN 3000989\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"dtsabyGqeRu9"},"source":["# **Fine-tune the BERTimbau model**\n","> Here we fine-tune the BERTimbau model on our wikipedia dataset \n","\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"O-MRbwPS4Vh2"},"source":["## Separate the inputs_labels.txt file into training and testing datasets\n","\n","> We create a function ourselves since we have inputs and labels together in one file\n","\n"]},{"cell_type":"code","metadata":{"id":"l8GyAx7O5CC-","executionInfo":{"status":"ok","timestamp":1624506852081,"user_tz":180,"elapsed":88411,"user":{"displayName":"Ernany Schmitz","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhByvIFGp3xzbbo2QbRqZJxU3jtyMeDGqCBL-t8La0m3FA6rlaZPZ8a5QPtL6uQFcRZ1OshlrWUf1_aPWm6uytMFTa4X4lF-JqpwAMHUH8CbtaCNG_hQq2QjR2Z5LxSEFSoy7vxYVUIvx8fHuuANAuYr3dmW2sb1m4e55QnCBZ8gk5a5YtMqdhoVkrKOxjeKzEfpGat-YdjbHubeBi1MG6YCfCbHwVPc5LOeOQOoJNtIusrgRKb0kfP7Vg2wnfBj--No1mJWDfxPV_IzSZqNUfqwqYg3C7DprDTXUWU9x9Cj1YzBd8U0bNvEyVGGwoHAvGGlR2hp3MDNBbmbdO1oDzwGckubTeS3agumyTIYwzlL01cOe4MH8NC899KJYyE5AVd3xG2v2hyfZTPzMToGVtIKrUyXht92_Bi5-RBJyMN7PJuRwRQW7BRXpv2eXj2KQv2dB7yMBI8mJeXTaGwp8qc5HyKjjGviWKrHXxVIm6ZbW94N3MJ4kDUu55Q5qjYX-VdTBGf1pU7apC1omVbtfgOhnNI1YbJpdb4aotD4wOuBBlrlUMmknymUCCC5rhZa27vp-l4A4EgLcRBYh8SxKuzSWHA15FqlmhJU4IZoIjga55k8qfhuNulwlVgSqXHvVSOmeLNDw5fi_QapuxA8dp0KBLaCskDBidRNtbthV5nr4_poYisdAgc_LwgDhbJl14kZ3xJe-JQ68S77-jLtxI_21jDYM_YMXBnsKpLKrBFYMPNX-ZqQUdn-8hyogyV-Z14kA=s64","userId":"06748672095417157324"}}},"source":["import random\n","import math\n","\n","# open the relevant files\n","inputs_labels_path = '/content/drive/MyDrive/gectorptbrFolder/files/neural_files/inputs_labels.txt'\n","train_path = '/content/drive/MyDrive/gectorptbrFolder/files/neural_files/train.txt'\n","test_path = '/content/drive/MyDrive/gectorptbrFolder/files/neural_files/test.txt'\n","\n","# if the file is huge, we have to think of something else, \n","# such as \"linecache\" instead of reading everything into memory\n","def shuffle_split(inpath, outpath_1, outpath_2, proportion_1=0.8):\n","    assert proportion_1 < 1.0, 'proportion_1 must be smaller than 1.0'\n","\n","    with open(inpath, 'r') as f:\n","        lines = f.readlines()\n","    # append a newline in case the last line didn't end with one\n","    # so that when we shuffle, we do not end up with two lines\n","    # without the break character\n","    lines[-1] = lines[-1].rstrip('\\n') + '\\n'\n","\n","    random.shuffle(lines)\n","\n","    cutoff = math.floor(proportion_1*len(lines))\n","    with open(outpath_1, 'w') as f:\n","        f.writelines(lines[:cutoff])\n","    with open(outpath_2, 'w') as f:\n","        f.writelines(lines[cutoff:])\n","\n","shuffle_split(inputs_labels_path, train_path, test_path)"],"execution_count":28,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"qBFcK3gV44Gy"},"source":["## Run the script for fine-tuning\n","\n","Here we have to input:\n","*   The training dataset; \n","*   The test dataset;\n","*   The model directory, here as MODEL_DIR;\n","*   The transformer BERT model which will be fine-tuned;\n","*   Inform whether we want to lowercase the tokens or not (0 => no, 1 => yes). Note: the BERTimbau model was trained on cased sentences, so it would be a waste of information if we were to train on uncased (i.e. lowercased tokens only) sentences.\n","*   The number of epochs."]},{"cell_type":"code","metadata":{"id":"qKDezqqNFR7X","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1624512666776,"user_tz":180,"elapsed":404540,"user":{"displayName":"Ernany Schmitz","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhByvIFGp3xzbbo2QbRqZJxU3jtyMeDGqCBL-t8La0m3FA6rlaZPZ8a5QPtL6uQFcRZ1OshlrWUf1_aPWm6uytMFTa4X4lF-JqpwAMHUH8CbtaCNG_hQq2QjR2Z5LxSEFSoy7vxYVUIvx8fHuuANAuYr3dmW2sb1m4e55QnCBZ8gk5a5YtMqdhoVkrKOxjeKzEfpGat-YdjbHubeBi1MG6YCfCbHwVPc5LOeOQOoJNtIusrgRKb0kfP7Vg2wnfBj--No1mJWDfxPV_IzSZqNUfqwqYg3C7DprDTXUWU9x9Cj1YzBd8U0bNvEyVGGwoHAvGGlR2hp3MDNBbmbdO1oDzwGckubTeS3agumyTIYwzlL01cOe4MH8NC899KJYyE5AVd3xG2v2hyfZTPzMToGVtIKrUyXht92_Bi5-RBJyMN7PJuRwRQW7BRXpv2eXj2KQv2dB7yMBI8mJeXTaGwp8qc5HyKjjGviWKrHXxVIm6ZbW94N3MJ4kDUu55Q5qjYX-VdTBGf1pU7apC1omVbtfgOhnNI1YbJpdb4aotD4wOuBBlrlUMmknymUCCC5rhZa27vp-l4A4EgLcRBYh8SxKuzSWHA15FqlmhJU4IZoIjga55k8qfhuNulwlVgSqXHvVSOmeLNDw5fi_QapuxA8dp0KBLaCskDBidRNtbthV5nr4_poYisdAgc_LwgDhbJl14kZ3xJe-JQ68S77-jLtxI_21jDYM_YMXBnsKpLKrBFYMPNX-ZqQUdn-8hyogyV-Z14kA=s64","userId":"06748672095417157324"}},"outputId":"3ef0a3b1-0ee7-4280-f245-26ca33ed02f5"},"source":["### train the model\n","!cd /content/drive/MyDrive/gectorptbrFolder && python3 train.py --train_set files/neural_files/train.txt --dev_set files/neural_files/test.txt --model_dir MODEL_DIR --transformer_model bertimbau --lowercase_tokens 0 --n_epoch 5\n"],"execution_count":4,"outputs":[{"output_type":"stream","text":["2021-06-24 05:24:35.186882: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n","/usr/local/lib/python3.7/dist-packages/sklearn/utils/linear_assignment_.py:22: FutureWarning: The linear_assignment_ module is deprecated in 0.21 and will be removed from 0.23. Use scipy.optimize.linear_sum_assignment instead.\n","  FutureWarning)\n","1856985it [04:59, 6281.31it/s]Traceback (most recent call last):\n","  File \"/content/drive/MyDrive/gectorptbrFolder/gector/datareader.py\", line 83, in _read\n","    tokens = [Token(token) for token, tag in tokens_and_tags]\n","  File \"/content/drive/MyDrive/gectorptbrFolder/gector/datareader.py\", line 83, in <listcomp>\n","    tokens = [Token(token) for token, tag in tokens_and_tags]\n","  File \"<string>\", line 1, in __new__\n","KeyboardInterrupt\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"train.py\", line 308, in <module>\n","    main(args)\n","  File \"train.py\", line 124, in main\n","    tokens_to_add=tokens_to_add)\n","  File \"/usr/local/lib/python3.7/dist-packages/allennlp/data/vocabulary.py\", line 398, in from_instances\n","    for instance in Tqdm.tqdm(instances):\n","  File \"/usr/local/lib/python3.7/dist-packages/tqdm/std.py\", line 1104, in __iter__\n","    for obj in iterable:\n","  File \"/usr/local/lib/python3.7/dist-packages/allennlp/data/dataset_readers/dataset_reader.py\", line 49, in __iter__\n","    yield from instances\n","  File \"/content/drive/MyDrive/gectorptbrFolder/gector/datareader.py\", line 98, in _read\n","    yield instance\n","KeyboardInterrupt\n","1856985it [05:00, 6183.25it/s]\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"rPRHg8ErEfez"},"source":["## Make inference on a file\n","\n","Here we have to input:\n","*   The trained model (one of the models saved in MODEL_DIR); \n","*   The vocabulary folder in which there is the information of what the model encountered in the training dataset, e.g. the labels \\$KEEP or \\$TRANSFORM_VERB_VB_VBD;\n","*   The file to make the inference on, e.g. a file containing sentence such as 'Eles era feios.' so that we want the neural network to output 'Eles eram feios.';\n","*   The file where the inference is outputted to;\n","*   The transformer model which we fine-tuned in the training.\n","\n","\n","\n","\n","\n","\n","\n"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mzc3uGmeErq3","executionInfo":{"status":"ok","timestamp":1623618392160,"user_tz":180,"elapsed":6869,"user":{"displayName":"Ernany Schmitz","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgGqQW6gMRNVUUO_PJwr7ZgYt6bxDagsjk1tiViGzKgIT3cguJGMnvN6AkVrcCA2KsDcFsMeBLp8pjQTuJ4URHkG6ya6-nrFgYmINYC6nWmOsdn7Z9d-ZmAWZ695KHENkgkfLa0llRfXzV8KBlXd3lyVTMuDmFF2nCKmK--h5go9smzd5QKyYZ7rBEanUciWOxBqmaIW6WDAZuEx8ioC_lOI41mIpNlNBWO0iIeLNZIiwhyviDHKpth1u8NknCVOGoZeDyZWNSY4p-cAj1zf-YuJVgy24OKb974nSqAMYKkT3q4QbByjXbCWI4dYj49PH_v94BW1Jp9q6JWPnhC1ggW_UJrIQlzm12a6eHwdNALLkivqaBJaIpX1LeHNq4D2q5xR7MdrQ4btUbdx3s7M1pRbm0zN_6CS1P5DqLEtsviAf3wiuf_QjZkXRxX-dbX7Ma8MZAWfXHClJHjXZ3h6fu0hIeimrFw_NRNKvtkK29JbcPIhFpGRfO6ZmmL721RCX5RCoTbkrVEhHss8yurUQgrVnVrscA3DyjxtKaSmd5Eg9ZcwCb-LEEWTDSCOPTUI2oeMvKnqM6qUMU3yFymkhX1T-U3T3IcT4fgAW3w2KIFu73K9VDfqqdZ1bAP4ycPgH1mNhQy7OVcNsMIxPewd-pJJWU3cGwBWQbPlthi_Mmde5DJayPdaWHP333jEKTEtV-Ule3A7cheWVypgvArYkj-CLkMvk3iH5UAtBbdw0NOJfgIYhmy2YFbcuMo0rnC2GVNWw=s64","userId":"06748672095417157324"}},"outputId":"da049a37-b94e-4bf5-c207-94c1ff1b35fa"},"source":["!cd /content/drive/MyDrive/gectorptbrFolder && python3 predict.py --model_path MODEL_DIR/model_state_epoch_4.th --vocab_path MODEL_DIR/vocabulary/ --input_file eval_after_train.txt --output_file OUTPUT_FILE.txt --transformer_model bertimbau\n"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Traceback (most recent call last):\n","  File \"predict.py\", line 4, in <module>\n","    from gector.gec_model import GecBERTModel\n","  File \"/content/drive/MyDrive/gectorptbrFolder/gector/gec_model.py\", line 8, in <module>\n","    from allennlp.data.dataset import Batch\n","ModuleNotFoundError: No module named 'allennlp'\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"dtCR_IuiLpQ9"},"source":[""],"execution_count":null,"outputs":[]}]}